# Prometheus Alerting Rules for MINIMINIMOON Performance Monitoring
# ====================================================================

groups:
  - name: miniminimoon_performance
    interval: 10s
    rules:
      # P95 Latency SLA Violations
      - alert: HighLatencySanitization
        expr: miniminimoon_pipeline_latency_milliseconds{node="sanitization",quantile="0.95"} > 2.2
        for: 1m
        labels:
          severity: warning
          component: sanitization
        annotations:
          summary: "Sanitization p95 latency exceeds budget"
          description: "Sanitization node p95 latency is {{ $value }}ms (budget: 2.0ms + 10% tolerance)"

      - alert: HighLatencyPlanProcessing
        expr: miniminimoon_pipeline_latency_milliseconds{node="plan_processing",quantile="0.95"} > 3.3
        for: 1m
        labels:
          severity: warning
          component: plan_processing
        annotations:
          summary: "Plan processing p95 latency exceeds budget"
          description: "Plan processing node p95 latency is {{ $value }}ms (budget: 3.0ms + 10% tolerance)"

      - alert: HighLatencyDocumentSegmentation
        expr: miniminimoon_pipeline_latency_milliseconds{node="document_segmentation",quantile="0.95"} > 4.4
        for: 1m
        labels:
          severity: warning
          component: document_segmentation
        annotations:
          summary: "Document segmentation p95 latency exceeds budget"
          description: "Document segmentation node p95 latency is {{ $value }}ms (budget: 4.0ms + 10% tolerance)"

      - alert: HighLatencyEmbedding
        expr: miniminimoon_pipeline_latency_milliseconds{node="embedding",quantile="0.95"} > 55.0
        for: 2m
        labels:
          severity: warning
          component: embedding
        annotations:
          summary: "Embedding p95 latency exceeds budget"
          description: "Embedding node p95 latency is {{ $value }}ms (budget: 50.0ms + 10% tolerance). Check batch optimization."

      - alert: CriticalLatencyEmbedding
        expr: miniminimoon_pipeline_latency_milliseconds{node="embedding",quantile="0.95"} > 80.0
        for: 1m
        labels:
          severity: critical
          component: embedding
        annotations:
          summary: "Embedding p95 latency critically high"
          description: "Embedding node p95 latency is {{ $value }}ms (exceeds p99 budget of 80ms). Immediate optimization required."

      - alert: HighLatencyResponsibilityDetection
        expr: miniminimoon_pipeline_latency_milliseconds{node="responsibility_detection",quantile="0.95"} > 11.0
        for: 1m
        labels:
          severity: warning
          component: responsibility_detection
        annotations:
          summary: "Responsibility detection p95 latency exceeds budget"
          description: "Responsibility detection node p95 latency is {{ $value }}ms (budget: 10.0ms + 10% tolerance)"

      - alert: HighLatencyContradictionDetection
        expr: miniminimoon_pipeline_latency_milliseconds{node="contradiction_detection",quantile="0.95"} > 8.8
        for: 1m
        labels:
          severity: warning
          component: contradiction_detection
        annotations:
          summary: "Contradiction detection p95 latency exceeds budget"
          description: "Contradiction detection node p95 latency is {{ $value }}ms (budget: 8.0ms + 10% tolerance)"

      - alert: HighLatencyMonetaryDetection
        expr: miniminimoon_pipeline_latency_milliseconds{node="monetary_detection",quantile="0.95"} > 5.5
        for: 1m
        labels:
          severity: warning
          component: monetary_detection
        annotations:
          summary: "Monetary detection p95 latency exceeds budget"
          description: "Monetary detection node p95 latency is {{ $value }}ms (budget: 5.0ms + 10% tolerance)"

      - alert: HighLatencyFeasibilityScoring
        expr: miniminimoon_pipeline_latency_milliseconds{node="feasibility_scoring",quantile="0.95"} > 6.6
        for: 1m
        labels:
          severity: warning
          component: feasibility_scoring
        annotations:
          summary: "Feasibility scoring p95 latency exceeds budget"
          description: "Feasibility scoring node p95 latency is {{ $value }}ms (budget: 6.0ms + 10% tolerance)"

      - alert: HighLatencyCausalDetection
        expr: miniminimoon_pipeline_latency_milliseconds{node="causal_detection",quantile="0.95"} > 7.7
        for: 1m
        labels:
          severity: warning
          component: causal_detection
        annotations:
          summary: "Causal detection p95 latency exceeds budget"
          description: "Causal detection node p95 latency is {{ $value }}ms (budget: 7.0ms + 10% tolerance)"

      - alert: HighLatencyTeoriaCambio
        expr: miniminimoon_pipeline_latency_milliseconds{node="teoria_cambio",quantile="0.95"} > 16.5
        for: 1m
        labels:
          severity: warning
          component: teoria_cambio
        annotations:
          summary: "Theory of change p95 latency exceeds budget"
          description: "Theory of change node p95 latency is {{ $value }}ms (budget: 15.0ms + 10% tolerance)"

      - alert: HighLatencyDAGValidation
        expr: miniminimoon_pipeline_latency_milliseconds{node="dag_validation",quantile="0.95"} > 11.0
        for: 1m
        labels:
          severity: warning
          component: dag_validation
        annotations:
          summary: "DAG validation p95 latency exceeds budget"
          description: "DAG validation node p95 latency is {{ $value }}ms (budget: 10.0ms + 10% tolerance)"

      # Special Contract Validation Target
      - alert: HighLatencyContractValidation
        expr: miniminimoon_pipeline_latency_milliseconds{node="contract_validation_ROUTING",quantile="0.95"} > 5.5
        for: 1m
        labels:
          severity: critical
          component: contract_validation
        annotations:
          summary: "Contract validation routing exceeds 5ms p95 target"
          description: "Contract validation p95 latency is {{ $value }}ms (target: 5.0ms + 10% tolerance)"

  # Circuit Breaker Alerts
  - name: miniminimoon_circuit_breakers
    interval: 10s
    rules:
      - alert: CircuitBreakerOpened
        expr: rate(miniminimoon_circuit_breaker_events_total{event="circuit_opened"}[5m]) > 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Circuit breaker {{ $labels.circuit }} has opened"
          description: "Circuit breaker for {{ $labels.circuit }} has transitioned to OPEN state, indicating repeated failures."

      - alert: CircuitBreakerHalfOpen
        expr: rate(miniminimoon_circuit_breaker_events_total{event="state_transition"}[5m]) > 0
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Circuit breaker {{ $labels.circuit }} is in HALF_OPEN state"
          description: "Circuit breaker for {{ $labels.circuit }} is testing recovery. Monitor for full recovery."

      - alert: CircuitBreakerSLAViolation
        expr: rate(miniminimoon_circuit_breaker_events_total{event="sla_violation"}[5m]) > 0
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Circuit breaker {{ $labels.circuit }} recovery time exceeds 2.0s SLA"
          description: "Recovery time for {{ $labels.circuit }} exceeds the 2.0s threshold."

      - alert: HighCircuitBreakerEventRate
        expr: rate(miniminimoon_circuit_breaker_events_total[5m]) > 1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High rate of circuit breaker events"
          description: "Circuit breaker event rate is {{ $value }} events/sec, indicating system instability."

  # Performance Regression Detection
  - name: miniminimoon_regression
    interval: 30s
    rules:
      - alert: PerformanceRegression
        expr: |
          (
            miniminimoon_pipeline_latency_milliseconds{quantile="0.95"}
            / 
            miniminimoon_pipeline_latency_milliseconds{quantile="0.95"} offset 1h
          ) > 1.10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Performance regression detected on {{ $labels.node }}"
          description: "p95 latency for {{ $labels.node }} has increased by more than 10% in the last hour."

  # Throughput Monitoring
  - name: miniminimoon_throughput
    interval: 30s
    rules:
      - alert: LowThroughput
        expr: rate(miniminimoon_pipeline_latency_milliseconds_count[5m]) < 0.1
        for: 5m
        labels:
          severity: info
        annotations:
          summary: "Low throughput on {{ $labels.node }}"
          description: "Processing rate for {{ $labels.node }} is {{ $value }} requests/sec."

      - alert: NoActivity
        expr: increase(miniminimoon_pipeline_latency_milliseconds_count[10m]) == 0
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "No activity detected on {{ $labels.node }}"
          description: "Node {{ $labels.node }} has not processed any requests in the last 10 minutes."

  # Batch Processing SLA Monitoring
  - name: batch_processing_sla
    interval: 30s
    rules:
      # Throughput SLA: 170 documents per hour
      - alert: BatchThroughputBelowSLA
        expr: batch_throughput_per_hour < 170
        for: 5m
        labels:
          severity: critical
          sla: throughput
        annotations:
          summary: "Batch throughput below 170 docs/hr SLA"
          description: "Current batch throughput is {{ $value }} documents/hr (target: 170 docs/hr). Immediate investigation required."

      - alert: BatchThroughputDegraded
        expr: batch_throughput_per_hour < 200 and batch_throughput_per_hour >= 170
        for: 10m
        labels:
          severity: warning
          sla: throughput
        annotations:
          summary: "Batch throughput approaching SLA threshold"
          description: "Current batch throughput is {{ $value }} documents/hr (target: 170 docs/hr, buffer: 200 docs/hr). Performance degradation detected."

      # P95 Latency SLA: 21.2 seconds per document
      - alert: BatchP95LatencyExceedsSLA
        expr: batch_document_processing_latency_seconds{quantile="0.95"} > 21.2
        for: 3m
        labels:
          severity: critical
          sla: latency
        annotations:
          summary: "Batch p95 latency exceeds 21.2s SLA"
          description: "Current p95 latency is {{ $value }}s (target: 21.2s). Document processing time exceeds SLA threshold."

      - alert: BatchP95LatencyWarning
        expr: batch_document_processing_latency_seconds{quantile="0.95"} > 18.0 and batch_document_processing_latency_seconds{quantile="0.95"} <= 21.2
        for: 5m
        labels:
          severity: warning
          sla: latency
        annotations:
          summary: "Batch p95 latency approaching SLA threshold"
          description: "Current p95 latency is {{ $value }}s (target: 21.2s, warning: 18.0s). Monitor for further degradation."

      # Worker Utilization Monitoring
      - alert: WorkerUtilizationLow
        expr: worker_utilization_percentage < 50
        for: 10m
        labels:
          severity: warning
          component: workers
        annotations:
          summary: "Worker utilization below 50%"
          description: "Worker {{ $labels.worker_id }} utilization is {{ $value }}% (threshold: 50%). Potential resource underutilization or queue starvation."

      - alert: WorkerUtilizationCriticallyLow
        expr: worker_utilization_percentage < 25
        for: 5m
        labels:
          severity: critical
          component: workers
        annotations:
          summary: "Worker utilization critically low"
          description: "Worker {{ $labels.worker_id }} utilization is {{ $value }}% (threshold: 25%). Investigation required - possible worker failure or queue issues."

      - alert: WorkerUtilizationHigh
        expr: worker_utilization_percentage > 95
        for: 15m
        labels:
          severity: info
          component: workers
        annotations:
          summary: "Worker utilization very high"
          description: "Worker {{ $labels.worker_id }} utilization is {{ $value }}% (threshold: 95%). Consider scaling up worker capacity."

      # Queue Depth Monitoring
      - alert: QueueDepthHigh
        expr: queue_depth > 1000
        for: 5m
        labels:
          severity: warning
          component: queue
        annotations:
          summary: "Processing queue depth exceeds 1000"
          description: "Queue {{ $labels.queue_name }} depth is {{ $value }} documents (threshold: 1000). Backlog accumulating."

      - alert: QueueDepthCritical
        expr: queue_depth > 5000
        for: 2m
        labels:
          severity: critical
          component: queue
        annotations:
          summary: "Processing queue depth critically high"
          description: "Queue {{ $labels.queue_name }} depth is {{ $value }} documents (critical: 5000). System may be overwhelmed."

      - alert: QueueDepthGrowing
        expr: rate(queue_depth[10m]) > 10
        for: 10m
        labels:
          severity: warning
          component: queue
        annotations:
          summary: "Processing queue growing rapidly"
          description: "Queue {{ $labels.queue_name }} growing at {{ $value }} docs/sec. Throughput not keeping pace with ingestion."

      # Error Rate Monitoring
      - alert: BatchErrorRateHigh
        expr: rate(batch_documents_processed_total{status="error"}[5m]) / rate(batch_documents_processed_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          component: batch_processor
        annotations:
          summary: "Batch error rate exceeds 5%"
          description: "Current error rate is {{ $value | humanizePercentage }} (threshold: 5%). Investigate batch processing failures."

      - alert: BatchErrorRateCritical
        expr: rate(batch_documents_processed_total{status="error"}[5m]) / rate(batch_documents_processed_total[5m]) > 0.10
        for: 2m
        labels:
          severity: critical
          component: batch_processor
        annotations:
          summary: "Batch error rate exceeds 10%"
          description: "Current error rate is {{ $value | humanizePercentage }} (critical: 10%). Immediate intervention required."

      # Success Rate Monitoring
      - alert: BatchSuccessRateLow
        expr: rate(batch_documents_processed_total{status="success"}[10m]) / rate(batch_documents_processed_total[10m]) < 0.95
        for: 10m
        labels:
          severity: warning
          sla: success_rate
        annotations:
          summary: "Batch success rate below 95%"
          description: "Current success rate is {{ $value | humanizePercentage }} (target: 95%). Quality degradation detected."

      # Bottleneck Detection
      - alert: BatchProcessingBottleneck
        expr: |
          (
            batch_stage_processing_time_seconds{quantile="0.95"}
            / 
            avg(batch_stage_processing_time_seconds{quantile="0.95"})
          ) > 3.0
        for: 10m
        labels:
          severity: warning
          component: bottleneck
        annotations:
          summary: "Processing bottleneck detected in {{ $labels.stage }}"
          description: "Stage {{ $labels.stage }} p95 latency is 3x higher than average. Investigate for performance optimization."

  # Document Processing Metrics
  - name: document_processing
    interval: 30s
    rules:
      - alert: DocumentProcessingStalled
        expr: increase(batch_documents_processed_total[5m]) == 0 and queue_depth > 0
        for: 5m
        labels:
          severity: critical
          component: batch_processor
        annotations:
          summary: "Document processing has stalled"
          description: "No documents processed in last 5 minutes despite queue depth of {{ $value }}. System may be stuck."

      - alert: DocumentProcessingSlowStart
        expr: batch_throughput_per_hour < 50
        for: 2m
        labels:
          severity: info
          component: batch_processor
        annotations:
          summary: "Batch processing slow start detected"
          description: "Initial throughput is {{ $value }} docs/hr (expected ramp-up period). Monitor for normal acceleration."
