# üî• MINIMINIMOON - Sistema Integrado de Evaluaci√≥n de Pol√≠ticas P√∫blicas

## INTEGRACI√ìN COMPLETA DE DECATALOGO_PRINCIPAL.PY

**Versi√≥n:** 10.0 - Industrial Dec√°logo Integrated  
**Fecha:** Octubre 2025  
**Estado:** ‚úÖ PRODUCCI√ìN - TOTALMENTE OPERACIONAL

---

## üìã TABLA DE CONTENIDOS

1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Flujo Can√≥nico Completo](#flujo-can√≥nico-completo)
4. [Decatalogo_principal.py - El Motor Central](#decatalogo_principalpy---el-motor-central)
5. [Contratos de Datos e Inmutabilidad](#contratos-de-datos-e-inmutabilidad)
6. [M√≥dulos del Sistema](#m√≥dulos-del-sistema)
7. [Cuestionario Industrial (300 Preguntas)](#cuestionario-industrial-300-preguntas)
8. [Gu√≠a de Uso](#gu√≠a-de-uso)
9. [Innovaciones T√©cnicas](#innovaciones-t√©cnicas)

---

## üéØ RESUMEN EJECUTIVO

MINIMINIMOON es un sistema de evaluaci√≥n **orientado a conocimiento** que procesa Planes de Desarrollo Municipal para responder **300 preguntas espec√≠ficas** del cuestionario industrial (`decalogo_industrial.json`).

### El Sistema Opera As√≠:

```
ENTRADA: Plan de Desarrollo Municipal (PDF/TXT)
   ‚Üì
PROCESAMIENTO: 12 Etapas de An√°lisis Incremental
   ‚Üì
N√öCLEO: Decatalogo_principal.py (ExtractorEvidenciaIndustrialAvanzado)
   ‚Üì
SALIDA: Evaluaci√≥n Completa con Evidencia para 300 Preguntas
```

### ‚ú® Caracter√≠sticas Clave:

- **üéØ Orientado a Preguntas**: Cada componente genera evidencia para preguntas espec√≠ficas
- **üîó Flujo Determin√≠stico**: Orden can√≥nico garantizado con contratos de datos
- **üõ°Ô∏è Inmutabilidad**: Verificaci√≥n criptogr√°fica de integridad
- **üìä 10 Dimensiones**: An√°lisis multidimensional con teor√≠a de cambio
- **üßÆ Innovaciones Matem√°ticas**: Algoritmos causales avanzados
- **üåê Capacidades de Frontera**: NLP avanzado, embeddings multiling√ºes

---

## üèóÔ∏è ARQUITECTURA DEL SISTEMA

### Componentes Principales

```
MINIMINIMOON ORCHESTRATOR (Coordinador Central)
‚îú‚îÄ‚îÄ Core Processing Layer
‚îÇ   ‚îú‚îÄ‚îÄ plan_sanitizer.py (Limpieza de texto)
‚îÇ   ‚îú‚îÄ‚îÄ plan_processor.py (Extracci√≥n de metadatos)
‚îÇ   ‚îî‚îÄ‚îÄ document_segmenter.py (Segmentaci√≥n inteligente)
‚îÇ
‚îú‚îÄ‚îÄ Analysis Layer
‚îÇ   ‚îú‚îÄ‚îÄ responsibility_detector.py (Entidades responsables)
‚îÇ   ‚îú‚îÄ‚îÄ contradiction_detector.py (Inconsistencias)
‚îÇ   ‚îú‚îÄ‚îÄ monetary_detector.py (Valores monetarios)
‚îÇ   ‚îú‚îÄ‚îÄ feasibility_scorer.py (Viabilidad)
‚îÇ   ‚îú‚îÄ‚îÄ teoria_cambio.py (Teor√≠a de cambio)
‚îÇ   ‚îú‚îÄ‚îÄ causal_pattern_detector.py (Patrones causales)
‚îÇ   ‚îî‚îÄ‚îÄ dag_validation.py (Validaci√≥n estructural)
‚îÇ
‚îú‚îÄ‚îÄ **N√öCLEO DEL SISTEMA** üî•
‚îÇ   ‚îî‚îÄ‚îÄ Decatalogo_principal.py
‚îÇ       ‚îú‚îÄ‚îÄ ExtractorEvidenciaIndustrialAvanzado (Motor de b√∫squeda)
‚îÇ       ‚îú‚îÄ‚îÄ DecalogoContextoAvanzado (10 dimensiones)
‚îÇ       ‚îú‚îÄ‚îÄ DimensionDecalogoAvanzada (Evaluaci√≥n por dimensi√≥n)
‚îÇ       ‚îú‚îÄ‚îÄ OntologiaPoliticasAvanzada (Ontolog√≠a especializada)
‚îÇ       ‚îú‚îÄ‚îÄ MathematicalInnovations (Algoritmos causales)
‚îÇ       ‚îî‚îÄ‚îÄ TeoriaCambioAvanzada (Verificaci√≥n causal)
‚îÇ
‚îú‚îÄ‚îÄ Infrastructure Layer
‚îÇ   ‚îú‚îÄ‚îÄ evidence_registry.py (Registro de evidencia)
‚îÇ   ‚îú‚îÄ‚îÄ data_flow_contract.py (Contratos de datos)
‚îÇ   ‚îú‚îÄ‚îÄ miniminimoon_immutability.py (Verificaci√≥n de integridad)
‚îÇ   ‚îî‚îÄ‚îÄ questionnaire_engine.py (Motor de cuestionarios)
‚îÇ
‚îî‚îÄ‚îÄ Integration Layer
    ‚îú‚îÄ‚îÄ decalogo_loader.py (Carga de dec√°logos)
    ‚îú‚îÄ‚îÄ decalogo_pipeline_orchestrator.py (Orquestaci√≥n espec√≠fica)
    ‚îî‚îÄ‚îÄ decalogo_industrial.json (300 preguntas)
```

---

## üîÑ FLUJO CAN√ìNICO COMPLETO

### Flujo de 12 Etapas con Generaci√≥n Incremental de Evidencia

```mermaid
graph TD
    A[Plan de Desarrollo] --> B[1. Sanitization]
    B --> C[2. Plan Processing]
    B --> D[3. Document Segmentation]
    D --> E[4. Embedding Generation]
    B --> F[5. Responsibility Detection]
    B --> G[6. Contradiction Detection]
    B --> H[7. Monetary Detection]
    B --> I[8. Feasibility Scoring]
    F --> J[9. Teoria del Cambio]
    G --> J
    H --> J
    I --> J
    B --> K[10. Causal Pattern Detection]
    J --> L[11. DAG Validation]
    
    %% N√öCLEO DEL SISTEMA
    D --> M[12. DECATALOGO EVALUATION]
    E --> M
    F --> M
    G --> M
    H --> M
    I --> M
    J --> M
    K --> M
    
    M --> N[Evaluaci√≥n Completa]
    M --> O[Evidence Registry]
    M --> P[300 Respuestas]
```

### Descripci√≥n Granular de Cada Etapa

#### **Etapa 1: Sanitization** (`plan_sanitizer.py`)
- **Entrada**: Texto crudo del plan
- **Proceso**: Normalizaci√≥n Unicode, eliminaci√≥n de caracteres especiales
- **Salida**: `SANITIZED_TEXT`
- **Contrato**: Garantiza texto limpio UTF-8

#### **Etapa 2: Plan Processing** (`plan_processor.py`)
- **Entrada**: `SANITIZED_TEXT`
- **Proceso**: Extracci√≥n de metadatos (t√≠tulo, fecha, entidad)
- **Salida**: `METADATA`
- **Contribuci√≥n**: Contexto para todas las preguntas

#### **Etapa 3: Document Segmentation** (`document_segmenter.py`)
- **Entrada**: `SANITIZED_TEXT`
- **Proceso**: Divisi√≥n inteligente por p√°rrafos/secciones
- **Salida**: `SEGMENTS` (Lista de segmentos)
- **Contribuci√≥n**: Base para b√∫squeda de evidencia

#### **Etapa 4: Embedding Generation** (`embedding_model.py`)
- **Entrada**: `SEGMENTS`
- **Proceso**: Generaci√≥n de embeddings multiling√ºes
- **Salida**: `EMBEDDINGS` (Vectores densos)
- **Contribuci√≥n**: B√∫squeda sem√°ntica avanzada

#### **Etapa 5: Responsibility Detection** (`responsibility_detector.py`)
- **Entrada**: `SANITIZED_TEXT`
- **Proceso**: Detecci√≥n de entidades institucionales responsables
- **Salida**: `ENTITIES` (Lista de responsabilidades)
- **Contribuci√≥n**: Evidencia para preguntas D4 (Responsabilidades)

#### **Etapa 6: Contradiction Detection** (`contradiction_detector.py`)
- **Entrada**: `SANITIZED_TEXT`
- **Proceso**: Detecci√≥n de inconsistencias l√≥gicas
- **Salida**: `CONTRADICTIONS`
- **Contribuci√≥n**: Evidencia para preguntas D5 (Coherencia)

#### **Etapa 7: Monetary Detection** (`monetary_detector.py`)
- **Entrada**: `SANITIZED_TEXT`
- **Proceso**: Extracci√≥n de valores monetarios y presupuestos
- **Salida**: `MONETARY_VALUES`
- **Contribuci√≥n**: Evidencia para preguntas D3 (Recursos financieros)

#### **Etapa 8: Feasibility Scoring** (`feasibility_scorer.py`)
- **Entrada**: `SANITIZED_TEXT`
- **Proceso**: Evaluaci√≥n de viabilidad de objetivos
- **Salida**: `FEASIBILITY_SCORES`
- **Contribuci√≥n**: Evidencia para preguntas D1 (Coherencia estrat√©gica)

#### **Etapa 9: Teoria del Cambio** (`teoria_cambio.py`)
- **Entrada**: `SANITIZED_TEXT`, `ENTITIES`, `MONETARY_VALUES`
- **Proceso**: Construcci√≥n de cadena causal
- **Salida**: `TEORIA_CAMBIO`
- **Contribuci√≥n**: Evidencia para preguntas D1 (Marco l√≥gico)

#### **Etapa 10: Causal Pattern Detection** (`causal_pattern_detector.py`)
- **Entrada**: `SANITIZED_TEXT`
- **Proceso**: Detecci√≥n de patrones causales
- **Salida**: `CAUSAL_PATTERNS`
- **Contribuci√≥n**: Evidencia para an√°lisis causal

#### **Etapa 11: DAG Validation** (`dag_validation.py`)
- **Entrada**: `TEORIA_CAMBIO`
- **Proceso**: Validaci√≥n de estructura DAG
- **Salida**: `DAG_STRUCTURE`
- **Contribuci√≥n**: Verificaci√≥n de coherencia estructural

#### **Etapa 12: DECATALOGO EVALUATION** üî• (`Decatalogo_principal.py`)
- **Entrada**: TODAS las salidas anteriores
- **Proceso**: Evaluaci√≥n avanzada con `ExtractorEvidenciaIndustrialAvanzado`
- **Salida**: Evaluaci√≥n completa con evidencia para 300 preguntas
- **Componentes Internos**:
  1. Inicializaci√≥n del extractor con documentos segmentados
  2. Precomputaci√≥n de embeddings avanzados
  3. An√°lisis estructural del documento
  4. Iteraci√≥n sobre 10 dimensiones del dec√°logo
  5. B√∫squeda de evidencia causal por dimensi√≥n
  6. Evaluaci√≥n de coherencia y KPIs
  7. Generaci√≥n de matriz de riesgos
  8. An√°lisis de interdependencias
  9. C√°lculo de cobertura de preguntas
  10. Registro en `evidence_registry`

---

## üî• DECATALOGO_PRINCIPAL.PY - EL MOTOR CENTRAL

### ¬øPor qu√© es el n√∫cleo del sistema?

`Decatalogo_principal.py` es el **motor de conocimiento** que integra todos los an√°lisis previos para generar respuestas espec√≠ficas al cuestionario industrial.

### Clase: `ExtractorEvidenciaIndustrialAvanzado`

**Prop√≥sito**: Buscar evidencia en el documento que responda preguntas espec√≠ficas del dec√°logo.

#### Inicializaci√≥n:
```python
extractor = ExtractorEvidenciaIndustrialAvanzado(
    documentos=[(pagina, texto), ...],  # Lista de tuplas (p√°gina, texto)
    nombre_plan="Plan_Municipal_2024"
)
```

#### Capacidades Avanzadas:

1. **Precomputaci√≥n de Embeddings**:
   - Genera embeddings para todos los segmentos
   - Almacena metadatos enriquecidos (densidad num√©rica, fechas, montos)
   - Clasificaci√≥n autom√°tica de tipo de contenido

2. **An√°lisis de Caracter√≠sticas del Texto**:
   - Densidad num√©rica (indicadores)
   - Densidad de fechas (cronogramas)
   - Densidad monetaria (presupuestos)
   - Complejidad sint√°ctica (normatividad)

3. **B√∫squeda de Evidencia Multi-Criterio**:
```python
evidencias = extractor.buscar_evidencia_causal_avanzada(
    query="Desarrollo sostenible y medio ambiente",
    conceptos_clave=["sostenibilidad", "biodiversidad", "clima"],
    top_k=10,
    umbral_certeza=0.6,
    pesos_criterios={
        "similitud_semantica": 0.35,
        "relevancia_conceptual": 0.30,
        "densidad_causal": 0.20,
        "calidad_contenido": 0.15
    }
)
```

4. **Scoring Multi-Dimensional**:
   - **Similitud Sem√°ntica**: Coseno entre embeddings
   - **Relevancia Conceptual**: Coincidencia con ontolog√≠a
   - **Densidad Causal**: Presencia de patrones causales
   - **Calidad del Contenido**: Longitud, densidad informativa

#### M√©todos Principales:

| M√©todo | Prop√≥sito | Retorna |
|--------|-----------|---------|
| `_precomputar_embeddings_avanzados()` | Genera embeddings de todos los segmentos | `torch.Tensor` |
| `_extraer_caracteristicas_texto()` | Analiza caracter√≠sticas del texto | `Dict[str, float]` |
| `buscar_evidencia_causal_avanzada()` | B√∫squeda multi-criterio de evidencia | `List[Dict]` |
| `_calcular_densidad_causal_avanzada()` | Mide densidad de patrones causales | `Dict[str, float]` |
| `_calcular_relevancia_conceptual_avanzada()` | Mide relevancia a conceptos | `float` |
| `_diversificar_resultados()` | Evita resultados redundantes | `List[Dict]` |

### Clase: `DimensionDecalogoAvanzada`

Representa una dimensi√≥n del dec√°logo (1 de 10).

#### Estructura:
```python
@dataclass(frozen=True)
class DimensionDecalogoAvanzada:
    id: int  # 1-10
    nombre: str
    cluster: str
    teoria_cambio: TeoriaCambioAvanzada
    eslabones: List[EslabonCadenaAvanzado]
    prioridad_estrategica: float  # 0.1-3.0
    complejidad_implementacion: float  # 0-1
    interdependencias: List[int]
```

#### M√©todos de Evaluaci√≥n:

1. **`evaluar_coherencia_causal_avanzada()`**:
   - Analiza la coherencia interna de la dimensi√≥n
   - Retorna: `Dict` con scores de coherencia

2. **`calcular_kpi_global_avanzado()`**:
   - Calcula KPIs agregados de la dimensi√≥n
   - Retorna: `Dict` con KPIs normalizados

3. **`generar_matriz_riesgos_avanzada()`**:
   - Identifica riesgos por tipo de eslab√≥n
   - Retorna: `Dict` con clasificaci√≥n de riesgos

### Clase: `MathematicalInnovations`

Algoritmos matem√°ticos avanzados para an√°lisis causal.

#### M√©todos Principales:

1. **`calculate_causal_strength(graph, source, target)`**:
   - Calcula fuerza causal entre nodos
   - Usa: Teor√≠a de grafos + centralidad + caminos m√∫ltiples

2. **`bayesian_evidence_integration(evidences, priors)`**:
   - Integraci√≥n bayesiana de evidencias
   - Actualizaci√≥n iterativa de posteriors

3. **`entropy_based_complexity(elements)`**:
   - Mide complejidad usando entrop√≠a de Shannon
   - Normaliza por m√°xima entrop√≠a posible

4. **`fuzzy_logic_aggregation(values, weights)`**:
   - Agregaci√≥n difusa con m√∫ltiples operadores
   - Retorna: T-normas, T-conormas, OWA

### Clase: `OntologiaPoliticasAvanzada`

Ontolog√≠a especializada en pol√≠ticas p√∫blicas.

#### Componentes:

1. **Dimensiones**: 5 categor√≠as principales
   - Social avanzado
   - Econ√≥mico transformacional
   - Ambiental regenerativo
   - Institucional transformativo
   - Territorial inteligente

2. **Relaciones Causales**: Mapeo de relaciones causa-efecto

3. **Indicadores ODS**: Alineaci√≥n con Objetivos de Desarrollo Sostenible

4. **Patrones Ling√º√≠sticos**: Expresiones regulares para detecci√≥n

5. **Vocabulario Especializado**: T√©rminos t√©cnicos por √°rea

#### M√©todo Principal:
```python
ontologia = OntologiaPoliticasAvanzada.cargar_ontologia_avanzada()
patrones = ontologia.buscar_patrones_avanzados(
    texto="Plan de desarrollo sostenible",
    categoria="indicadores_desempe√±o"
)
```

---

## üõ°Ô∏è CONTRATOS DE DATOS E INMUTABILIDAD

### Sistema de Contratos de Datos (`data_flow_contract.py`)

#### Tipos de Datos Definidos:

```python
class DataType(Enum):
    # Tipos b√°sicos
    RAW_TEXT = "raw_text"
    SANITIZED_TEXT = "sanitized_text"
    SEGMENTS = "segments"
    EMBEDDINGS = "embeddings"
    ENTITIES = "entities"
    CONTRADICTIONS = "contradictions"
    MONETARY_VALUES = "monetary_values"
    FEASIBILITY_SCORES = "feasibility_scores"
    CAUSAL_PATTERNS = "causal_patterns"
    TEORIA_CAMBIO = "teoria_cambio"
    DAG_STRUCTURE = "dag_structure"
    METADATA = "metadata"
    
    # Tipos espec√≠ficos de Decatalogo_principal.py
    DECATALOGO_EVIDENCIA = "decatalogo_evidencia"
    DECATALOGO_DIMENSION = "decatalogo_dimension"
    DECATALOGO_CLUSTER = "decatalogo_cluster"
    ONTOLOGIA_PATTERNS = "ontologia_patterns"
    ADVANCED_EMBEDDINGS = "advanced_embeddings"
    CAUSAL_COEFFICIENTS = "causal_coefficients"
```

#### Contrato: `decatalogo_evaluation`

```python
NodeContract(
    node_name="decatalogo_evaluation",
    required_inputs={
        "plan_text": DataType.SANITIZED_TEXT,
        "segments": DataType.SEGMENTS,
        "responsibilities": DataType.ENTITIES,
        "monetary": DataType.MONETARY_VALUES,
        "feasibility": DataType.FEASIBILITY_SCORES,
        "teoria_cambio": DataType.TEORIA_CAMBIO,
        "causal_patterns": DataType.CAUSAL_PATTERNS
    },
    required_outputs={
        "evaluacion_por_dimension": DataType.DECATALOGO_DIMENSION,
        "evidencias_globales": DataType.DECATALOGO_EVIDENCIA,
        "metricas_globales": DataType.METADATA,
        "analisis_clusters": DataType.DECATALOGO_CLUSTER,
        "interdependencias_globales": DataType.DAG_STRUCTURE
    },
    validation_rules=[...],  # 7 reglas de validaci√≥n
    dependencies=["sanitization", "segmentation", ...],
    performance_budget_ms=30000  # 30 segundos
)
```

#### Validaci√≥n Especializada:

```python
validator = CanonicalFlowValidator()
validation_report = validator.validate_decatalogo_integration(results)
```

Verifica:
- ‚úÖ Estructura b√°sica correcta
- ‚úÖ Metadatos completos
- ‚úÖ M√©tricas globales en rangos v√°lidos
- ‚úÖ Evaluaci√≥n por dimensi√≥n completa
- ‚úÖ An√°lisis de clusters presente
- ‚úÖ Cobertura de preguntas > 30%
- ‚úÖ Integraci√≥n de componentes

### Sistema de Inmutabilidad (`miniminimoon_immutability.py`)

#### Verificaci√≥n Criptogr√°fica:

```python
contract = ImmutabilityContract()

# Verificar Decatalogo_principal.py
verification = contract.verify_decatalogo_integration()

# Checks realizados:
# 1. M√≥dulo importable
# 2. Clases cr√≠ticas presentes
# 3. Funci√≥n de contexto disponible
# 4. Hash de integridad
# 5. Capacidades de frontera
```

#### Freeze del Estado:

```python
# Congelar estado para garantizar reproducibilidad
contract.freeze_integration()

# Genera:
# - Hashes de todos los m√≥dulos
# - Firma criptogr√°fica HMAC
# - Registro de componentes
# - Archivo: integration_freeze.json
```

---

## üì¶ M√ìDULOS DEL SISTEMA

### M√≥dulos Core

| M√≥dulo | Prop√≥sito | Innovaci√≥n Principal |
|--------|-----------|---------------------|
| `plan_sanitizer.py` | Limpieza de texto | Normalizaci√≥n Unicode avanzada |
| `plan_processor.py` | Extracci√≥n de metadatos | Detecci√≥n inteligente de estructura |
| `document_segmenter.py` | Segmentaci√≥n | Estrategias m√∫ltiples (p√°rrafo, secci√≥n) |
| `embedding_model.py` | Embeddings | Modelo multiling√ºe optimizado |

### M√≥dulos de An√°lisis

| M√≥dulo | Prop√≥sito | Innovaci√≥n Principal |
|--------|-----------|---------------------|
| `responsibility_detector.py` | Detecci√≥n de entidades | NER especializado en instituciones |
| `contradiction_detector.py` | Detecci√≥n de inconsistencias | An√°lisis l√≥gico avanzado |
| `monetary_detector.py` | Extracci√≥n de valores | Parsing multi-formato de monedas |
| `feasibility_scorer.py` | Evaluaci√≥n de viabilidad | Scoring multi-dimensional |
| `teoria_cambio.py` | Teor√≠a de cambio | Construcci√≥n de DAG causal |
| `causal_pattern_detector.py` | Patrones causales | Detecci√≥n de relaciones causa-efecto |
| `dag_validation.py` | Validaci√≥n DAG | Verificaci√≥n de acicl icidad |

### M√≥dulo Nuclear

| M√≥dulo | Prop√≥sito | Innovaci√≥n Principal |
|--------|-----------|---------------------|
| **`Decatalogo_principal.py`** | **Motor de evaluaci√≥n** | **Sistema completo de extracci√≥n de conocimiento** |

Componentes internos:
- `ExtractorEvidenciaIndustrialAvanzado`: B√∫squeda avanzada
- `DecalogoContextoAvanzado`: 10 dimensiones
- `DimensionDecalogoAvanzada`: Evaluaci√≥n por dimensi√≥n
- `OntologiaPoliticasAvanzada`: Ontolog√≠a especializada
- `MathematicalInnovations`: Algoritmos causales
- `TeoriaCambioAvanzada`: Verificaci√≥n causal
- `EslabonCadenaAvanzado`: Eslabones de cadena de valor

### M√≥dulos de Infraestructura

| M√≥dulo | Prop√≥sito | Innovaci√≥n Principal |
|--------|-----------|---------------------|
| `evidence_registry.py` | Registro de evidencia | Trazabilidad completa |
| `data_flow_contract.py` | Contratos de datos | Validaci√≥n autom√°tica |
| `miniminimoon_immutability.py` | Verificaci√≥n de integridad | Firma criptogr√°fica |
| `questionnaire_engine.py` | Motor de cuestionarios | Generaci√≥n din√°mica |

---

## üìù CUESTIONARIO INDUSTRIAL (300 PREGUNTAS)

### Estructura del Cuestionario (`decalogo_industrial.json`)

```json
{
  "version": "1.0",
  "schema": "decalogo_causal_questions_v1",
  "total": 300,
  "questions": [
    {
      "id": "D1-Q1",
      "dimension": "D1",
      "question_no": 1,
      "point_code": "P1",
      "point_title": "T√≠tulo del punto",
      "prompt": "¬øPregunta espec√≠fica?",
      "hints": ["pista1", "pista2", ...]
    },
    ...
  ]
}
```

### Dimensiones del Dec√°logo

| Dimensi√≥n | Nombre | Preguntas | Enfoque |
|-----------|--------|-----------|---------|
| **D1** | Derechos de las mujeres e igualdad de g√©nero | ~30 | Equidad, violencia, participaci√≥n |
| **D2** | Ni√±os, ni√±as y adolescentes | ~30 | Protecci√≥n, educaci√≥n, salud |
| **D3** | Personas mayores | ~30 | Cuidado, pensiones, inclusi√≥n |
| **D4** | Personas con discapacidad | ~30 | Accesibilidad, inclusi√≥n laboral |
| **D5** | Grupos √©tnicos | ~30 | Derechos territoriales, cultura |
| **D6** | V√≠ctimas del conflicto | ~30 | Reparaci√≥n, memoria, verdad |
| **D7** | Reincorporaci√≥n y reconciliaci√≥n | ~30 | Paz territorial, convivencia |
| **D8** | Participaci√≥n ciudadana | ~30 | Democracia, transparencia |
| **D9** | Desarrollo sostenible | ~30 | Ambiente, clima, biodiversidad |
| **D10** | Gesti√≥n p√∫blica integral | ~30 | Eficiencia, innovaci√≥n, TIC |

### C√≥mo el Sistema Genera Respuestas

#### Flujo de Generaci√≥n de Evidencia:

```
1. CARGA DEL CUESTIONARIO
   ‚îú‚îÄ‚îÄ Leer decalogo_industrial.json
   ‚îî‚îÄ‚îÄ Mapear 300 preguntas a dimensiones

2. PROCESAMIENTO DEL PLAN
   ‚îú‚îÄ‚îÄ Sanitizaci√≥n y segmentaci√≥n
   ‚îú‚îÄ‚îÄ An√°lisis por componentes especializados
   ‚îî‚îÄ‚îÄ Generaci√≥n de evidencia preliminar

3. EVALUACI√ìN POR DIMENSI√ìN (x10)
   Para cada dimensi√≥n D1-D10:
   ‚îú‚îÄ‚îÄ Extraer conceptos clave de eslabones
   ‚îú‚îÄ‚îÄ Buscar evidencia usando ExtractorEvidenciaIndustrialAvanzado
   ‚îÇ   ‚îú‚îÄ‚îÄ Similitud sem√°ntica con embeddings
   ‚îÇ   ‚îú‚îÄ‚îÄ Relevancia conceptual con ontolog√≠a
   ‚îÇ   ‚îú‚îÄ‚îÄ Densidad causal con patrones
   ‚îÇ   ‚îî‚îÄ‚îÄ Calidad de contenido con heur√≠sticas
   ‚îú‚îÄ‚îÄ Evaluar coherencia causal
   ‚îú‚îÄ‚îÄ Calcular KPIs
   ‚îú‚îÄ‚îÄ Generar matriz de riesgos
   ‚îî‚îÄ‚îÄ Registrar evidencia en evidence_registry

4. MAPEO EVIDENCIA ‚Üí PREGUNTAS
   Para cada evidencia encontrada:
   ‚îú‚îÄ‚îÄ Determinar tipo de contenido
   ‚îú‚îÄ‚îÄ Calcular aplicabilidad a preguntas
   ‚îú‚îÄ‚îÄ Asignar evidencia a IDs de preguntas
   ‚îî‚îÄ‚îÄ Registrar con confianza

5. AGREGACI√ìN Y COBERTURA
   ‚îú‚îÄ‚îÄ Calcular cobertura de las 300 preguntas
   ‚îú‚îÄ‚îÄ Identificar gaps de evidencia
   ‚îî‚îÄ‚îÄ Generar reporte final
```

#### Ejemplo de Mapeo:

```python
# Evidencia encontrada
evidencia = {
    "texto": "Presupuesto de $500 millones para programa de equidad de g√©nero",
    "tipo_contenido": "presupuestal_financiero",
    "score_final": 0.85,
    "densidad_monetaria": 8.5,
    ...
}

# Mapeo a preguntas
preguntas_aplicables = [
    "D1-Q5",   # Recursos asignados
    "D1-Q10",  # Presupuesto equidad
    "D1-Q15",  # Financiaci√≥n programas
    "D1-Q20",  # Sostenibilidad financiera
    ...
]

# Registro
evidence_registry.register(
    source_component="decatalogo_extractor",
    evidence_type="presupuestal_financiero",
    content=evidencia,
    confidence=0.85,
    applicable_questions=preguntas_aplicables
)
```

---

## üöÄ GU√çA DE USO

### Instalaci√≥n

```bash
# 1. Clonar repositorio
git clone <repo-url>
cd MINIMINIMOON-main

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Descargar modelos
python -m spacy download es_core_news_lg

# 4. Verificar instalaci√≥n
python miniminimoon_orchestrator.py --help
```

### Uso B√°sico

```bash
# Procesar un plan
python miniminimoon_orchestrator.py \
    /ruta/al/plan_desarrollo.pdf \
    --output resultados_evaluacion.json

# Con configuraci√≥n personalizada
python miniminimoon_orchestrator.py \
    /ruta/al/plan_desarrollo.pdf \
    --config config_custom.json \
    --output resultados.json
```

### Uso Program√°tico

```python
from miniminimoon_orchestrator import MINIMINIMOONOrchestrator

# Inicializar orquestador
orchestrator = MINIMINIMOONOrchestrator(config_path="config.json")

# Procesar plan
results = orchestrator.process_plan("/ruta/al/plan.pdf")

# Acceder a evaluaci√≥n del dec√°logo
decatalogo_eval = results["decatalogo_evaluation"]

print(f"Coherencia global: {decatalogo_eval['metricas_globales']['coherencia_promedio']:.2%}")
print(f"KPI global: {decatalogo_eval['metricas_globales']['kpi_promedio']:.2%}")
print(f"Cobertura: {decatalogo_eval['cobertura_cuestionario_industrial']['porcentaje_cobertura']:.1f}%")

# Analizar dimensi√≥n espec√≠fica
dim1 = decatalogo_eval["evaluacion_por_dimension"]["D1 - G√©nero"]
print(f"\nDimensi√≥n 1 - Evidencias: {dim1['evidencias_encontradas']}")
print(f"Coherencia: {dim1['coherencia']['coherencia_global']:.2%}")
```

### Verificaci√≥n de Integridad

```bash
# Verificar componentes
python miniminimoon_immutability.py verify normal

# Congelar estado
python miniminimoon_immutability.py freeze

# Verificar contratos de datos
python data_flow_contract.py validate
```

### Configuraci√≥n Avanzada

```json
{
  "parallel_processing": true,
  "embedding_batch_size": 32,
  "segmentation_strategy": "paragraph",
  "context_window_size": 150,
  "error_tolerance": "medium",
  "log_level": "INFO",
  "cache_embeddings": true,
  "verification_level": "normal",
  "determinism": {
    "enabled": true,
    "seed": 42
  },
  "decatalogo": {
    "umbral_certeza": 0.6,
    "top_k_evidencias": 10,
    "pesos_criterios": {
      "similitud_semantica": 0.35,
      "relevancia_conceptual": 0.30,
      "densidad_causal": 0.20,
      "calidad_contenido": 0.15
    }
  }
}
```

---

## üí° INNOVACIONES T√âCNICAS

### 1. Extracci√≥n de Conocimiento Orientada a Preguntas

En lugar de un an√°lisis gen√©rico, **cada componente sabe exactamente qu√© preguntas debe responder**.

```python
# Ejemplo: monetary_detector sabe que contribuye a preguntas D3
for mon in monetary:
    evidence_registry.register(
        source_component="monetary_detector",
        evidence_type="monetary_value",
        content=mon,
        confidence=0.8,
        applicable_questions=[f"D3-Q{i}" for i in range(1, 51)]
    )
```

### 2. Scoring Multi-Criterio con Ponderaci√≥n

La b√∫squeda de evidencia no usa solo similitud sem√°ntica, sino **4 criterios ponderados**:

```python
score_final = (
    similitud_semantica * 0.35 +
    relevancia_conceptual * 0.30 +
    densidad_causal * 0.20 +
    calidad_contenido * 0.15
)
```

### 3. Precomputaci√≥n Inteligente

Todos los embeddings y an√°lisis estructurales se calculan **una sola vez** al inicio:

```python
def _inicializar_capacidades_avanzadas(self):
    self._precomputar_embeddings_avanzados()
    self._precomputar_tfidf()
    self._analizar_estructura_documental()
```

### 4. Clasificaci√≥n Autom√°tica de Contenido

Cada segmento se clasifica autom√°ticamente:

```python
tipos = [
    "presupuestal_financiero",
    "cronogramas_plazos",
    "normativo_legal",
    "indicadores_metricas",
    "narrativo_descriptivo"
]
```

### 5. An√°lisis Causal Multinivel

Usando teor√≠a de grafos + entrop√≠a + l√≥gica difusa:

```python
fuerza_causal = MathematicalInnovations.calculate_causal_strength(G, "insumos", "impactos")
complejidad = MathematicalInnovations.entropy_based_complexity(elementos)
agregacion = MathematicalInnovations.fuzzy_logic_aggregation(values, weights)
```

### 6. Contratos de Datos con Cach√©

Validaciones cacheadas con hash para evitar recomputaci√≥n:

```python
cached = validation_cache.get(data, node_name)
if cached is not None:
    return cached  # Hit rate: ~85%
```

### 7. Verificaci√≥n Criptogr√°fica

Cada m√≥dulo cr√≠tico tiene un hash SHA-256 verificable:

```python
module_hash = hashlib.sha256(source_code.encode()).hexdigest()
signature = hmac.new(HMAC_KEY, serialized, hashlib.sha256).digest()
```

### 8. Ontolog√≠a Especializada

5 dimensiones con vocabulario controlado y patrones ling√º√≠sticos:

```python
dimensiones = {
    "social_avanzado": [...],
    "economico_transformacional": [...],
    "ambiental_regenerativo": [...],
    "institucional_transformativo": [...],
    "territorial_inteligente": [...]
}
```

### 9. Integraci√≥n Bayesiana de Evidencias

Actualizaci√≥n iterativa de certeza probabil√≠stica:

```python
for evidence in evidences:
    posterior = (likelihood * prior) / denominator
    posterior = max(0.01, min(0.99, posterior))  # Regularizaci√≥n
```

### 10. Diversificaci√≥n de Resultados

Evita redundancia en evidencias similares:

```python
def _diversificar_resultados(self, resultados, top_k):
    # Algoritmo de m√°xima diversidad marginal (MMR)
    # Balancea relevancia con diversidad
    return resultados_diversos[:top_k]
```

---

## üìä FORMATO DE SALIDA

### Estructura del JSON de Resultados

```json
{
  "plan_path": "/ruta/plan.pdf",
  "plan_name": "Plan_Municipal_2024",
  "executed_nodes": [
    "sanitization",
    "plan_processing",
    ...
    "decatalogo_evaluation"
  ],
  "decatalogo_evaluation": {
    "metadata": {
      "plan_evaluado": "Plan_Municipal_2024",
      "fecha_evaluacion": "2025-10-05 14:30:00",
      "version_sistema": "10.0-industrial-decatalogo-integrated",
      "total_dimensiones": 10,
      "total_eslabones": 40
    },
    "metricas_globales": {
      "coherencia_promedio": 0.78,
      "kpi_promedio": 0.82,
      "evidencias_totales": 156,
      "dimensiones_evaluadas": 10,
      "cobertura_preguntas": 67.5
    },
    "evaluacion_por_dimension": {
      "D1 - G√©nero": {
        "dimension_id": 1,
        "coherencia": {...},
        "kpis": {...},
        "evidencias_encontradas": 18,
        "evidencias_top_5": [...]
      },
      ...
    },
    "analisis_clusters": {...},
    "cobertura_cuestionario_industrial": {
      "total_preguntas": 300,
      "preguntas_cubiertas_estimadas": 203,
      "porcentaje_cobertura": 67.5,
      "evidencias_alta_calidad": 89
    }
  },
  "execution_summary": {...},
  "immutability_signature": "Ag7x..."
}
```

---

## üéì CONCLUSI√ìN

MINIMINIMOON es un sistema **orientado a conocimiento** que:

‚úÖ **Procesa** planes de desarrollo de manera exhaustiva  
‚úÖ **Extrae** evidencia espec√≠fica para 300 preguntas  
‚úÖ **Eval√∫a** 10 dimensiones con an√°lisis causal avanzado  
‚úÖ **Garantiza** integridad con contratos de datos y verificaci√≥n criptogr√°fica  
‚úÖ **Integra** Decatalogo_principal.py como motor central de evaluaci√≥n  

### Decatalogo_principal.py NO es un archivo m√°s - ES EL N√öCLEO DEL SISTEMA

Es el componente que:
- Orquesta toda la extracci√≥n de conocimiento
- Conecta an√°lisis previos con preguntas espec√≠ficas
- Implementa algoritmos matem√°ticos de frontera
- Genera la evaluaci√≥n final completa

**¬°AHORA S√ç EST√Å COMPLETAMENTE INTEGRADO Y OPERACIONAL!** üöÄ

---

**Autor**: Sistema MINIMINIMOON v10.0  
**Fecha**: Octubre 2025  
**Licencia**: Uso acad√©mico e institucional

